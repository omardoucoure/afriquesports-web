# Afrique Sports Infrastructure Configuration
# This file is git-tracked and persists across Claude Code sessions

runpod:
  # OLD PODS (TERMINATED): wfl4o3ns1tizo1, 5x6ah8amw9oo9e, qbjo7w9adplhia (7B)

  # NEW 70B + RAG POD (to be created)
  # Instructions: scripts/runpod-70b-rag/README.md
  pod_70b:
    pod_id: ""  # UPDATE after creating pod
    pod_name: "afrique-sports-70b-rag"
    template: runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04
    gpu: A100 80GB  # Required for 70B
    location: EU-RO-1 or US  # Cheapest A100 locations
    cost: $1.89/hr
    status: pending_creation

    # Services
    vllm:
      port: 8000
      model: meta-llama/Llama-3.1-70B-Instruct
      api_key: sk-afrique

    rag:
      port: 8100
      collection: afrique_sports_articles
      documents: 23196

    # Setup
    setup_script: scripts/runpod-70b-rag/setup.sh
    sync_script: scripts/runpod-70b-rag/sync-rag-data.sh

  # LEGACY 7B POD (stopped)
  pod_7b:
    pod_id: qbjo7w9adplhia
    pod_name: redundant_lavender_alligator-migration
    template: vllm/vllm-openai:latest
    gpu: RTX A5000 24GB
    location: CA
    cost: $0.270/hr
    status: stopped

  # SSH (limited functionality on vLLM template - API-first design)
  ssh_tunnel: qbjo7w9adplhia-64411022@ssh.runpod.io
  ssh_tcp: root@69.30.85.175:22147
  ssh_key: ~/.ssh/id_ed25519
  ssh_note: "SSH has limited PTY support on vLLM template - use HTTP API instead"

  # vLLM API Configuration
  vllm:
    # Status: ✅ WORKING - AFCON Merged Model Deployed (2025-12-27)

    # Public HTTP endpoints via RunPod proxy
    base_url: https://qbjo7w9adplhia-8000.proxy.runpod.net
    api_endpoint: https://qbjo7w9adplhia-8000.proxy.runpod.net/v1
    api_docs: https://qbjo7w9adplhia-8000.proxy.runpod.net/docs
    openapi_spec: https://qbjo7w9adplhia-8000.proxy.runpod.net/openapi.json

    # Internal endpoint (from within pod)
    internal_endpoint: http://localhost:8000/v1
    port: 8000

    # Authentication ✅ CONFIGURED
    api_key: sk-1234  # Set via launch parameter --api-key
    auth_header: "Authorization: Bearer sk-1234"

    # Model configuration (Fine-tuned Vision-Language model)
    model: oxmo88/Qwen2.5-VL-7B-AFCON2025  # Fine-tuned for AFCON French commentary
    base_model: Qwen/Qwen2.5-VL-7B-Instruct  # Original base model
    huggingface_repo: https://huggingface.co/oxmo88/Qwen2.5-VL-7B-AFCON2025
    model_type: merged_lora  # LoRA adapter merged into base model
    fine_tuning:
      adapter_merged: true
      training_examples: 2000
      training_loss: 0.148
      domain: AFCON 2025 French commentary
    model_capabilities:
      - text_generation
      - vision_understanding  # Can process images
      - tool_calling  # Function calling support
      - afcon_commentary  # Fine-tuned specialty
    max_model_len: 32768  # 32k token context window
    dtype: bfloat16
    gpu_memory_utilization: 0.95
    tensor_parallel_size: 1

    # Vision capabilities
    vision:
      max_images_per_prompt: 4
      max_videos_per_prompt: 1
      allowed_media_path: /workspace

    # Tool calling
    tool_calling:
      enabled: true
      parser: hermes
      auto_tool_choice: true

    # LoRA support (NOT USED - using merged model instead)
    lora:
      enabled: false  # vLLM template doesn't support LoRA - using merged model
      note: "AFCON adapter merged into base model (oxmo88/Qwen2.5-VL-7B-AFCON2025)"
      max_loras: 4
      max_lora_rank: 64
      adapter_directory: /workspace/lora-adapters

      # Domain adapters configuration
      adapters:
        - name: fut-v1
          domain: FIFA Ultimate Team
          languages: [EN, FR]
          path: /workspace/lora-adapters/fut-v1
          websites:
            - fut-elite.com
            - fut-elite.fr
          status: pending_training

        - name: madrid-v1
          domain: Real Madrid News
          languages: [ES, EN]
          path: /workspace/lora-adapters/madrid-v1
          websites:
            - real-madrid-news.com
          status: pending_training

        - name: afrique-v1
          domain: African Sports (AFCON)
          languages: [FR]
          path: /workspace/lora-adapters/afrique-v1
          huggingface_adapter_repo: oxmo88/afrique-sports-afcon2025-adapter
          huggingface_merged_repo: oxmo88/Qwen2.5-VL-7B-AFCON2025
          websites:
            - afriquesports.net
          training_data: /workspace/training-data/afrique/afcon2025_training.jsonl
          training_examples: 2000
          training_completed: 2025-12-27
          training_loss: 0.148  # 94% reduction from 2.566
          deployment_method: merged_model
          status: deployed_to_vllm
          deployed_at: 2025-12-27
          vllm_model_name: oxmo88/Qwen2.5-VL-7B-AFCON2025
          priority: 1  # ✅ COMPLETED - Live in production

        - name: cuisine-v1
          domain: African Cuisine
          languages: [FR]
          path: /workspace/lora-adapters/cuisine-v1
          websites:
            - cuisine-africaine.net
          status: pending_training

      # Updated launch command (replace current parameters)
      launch_command: |
        --model Qwen/Qwen2.5-VL-7B-Instruct \
        --tensor-parallel-size 1 \
        --dtype bfloat16 \
        --gpu-memory-utilization 0.90 \
        --max-model-len 32768 \
        --host 0.0.0.0 \
        --api-key sk-1234 \
        --enable-auto-tool-choice \
        --tool-call-parser hermes \
        --limit-mm-per-prompt '{"image":4,"video":1}' \
        --allowed-local-media-path /workspace \
        --enable-lora \
        --max-loras 4 \
        --max-lora-rank 64 \
        --lora-modules fut-v1=/workspace/lora-adapters/fut-v1 \
        --lora-modules madrid-v1=/workspace/lora-adapters/madrid-v1 \
        --lora-modules afrique-v1=/workspace/lora-adapters/afrique-v1 \
        --lora-modules cuisine-v1=/workspace/lora-adapters/cuisine-v1

  # Training pod (on-demand for LoRA training)
  training_pod:
    pod_id: 5x0b0iznq43xu4
    pod_name: immediate_brown_moth
    gpu: RTX A5000 24GB
    location: CA
    cost: $0.270/hr
    status: running
    usage: "On-demand LoRA adapter training (stop when not training)"

    # Training configuration
    purpose: lora_training
    framework: axolotl
    shared_volume: /workspace  # Same volume as inference pod

    training_config:
      base_model: Qwen/Qwen2.5-VL-7B-Instruct
      lora_r: 64
      lora_alpha: 128
      lora_dropout: 0.05
      target_modules:
        - q_proj
        - k_proj
        - v_proj
        - o_proj
        - gate_proj
        - up_proj
        - down_proj
      batch_size: 4
      gradient_accumulation_steps: 4
      learning_rate: 2e-4
      num_epochs: 3
      warmup_steps: 100

    # Training data locations
    data_paths:
      afrique: /workspace/training-data/afrique/afcon2025_training.jsonl
      fut: /workspace/training-data/fut/
      madrid: /workspace/training-data/madrid/
      cuisine: /workspace/training-data/cuisine/

    # Output paths (shared with inference pod)
    output_paths:
      afrique: /workspace/lora-adapters/afrique-v1
      fut: /workspace/lora-adapters/fut-v1
      madrid: /workspace/lora-adapters/madrid-v1
      cuisine: /workspace/lora-adapters/cuisine-v1

    # Cost management
    recommended_usage: "Start only for training, stop when complete"
    estimated_training_time_per_adapter: "2-3 hours"
    estimated_cost_per_adapter: "$0.81"

  fine_tuning:
    framework: axolotl
    training_data: scripts/data-collection/data/afcon2025_training.jsonl
    config: scripts/data-collection/axolotl_config.yaml
    examples: 2000
    lora_r: 32
    lora_alpha: 64

digitalocean:
  ip: 159.223.103.16
  ssh_port: 22
  ssh_user: root
  agents:
    - name: live-commentary
      service: afrique-sports-commentary.service
      script: /opt/afrique-sports-commentary/live-commentary-agent.js
    - name: autonomous-match
      service: autonomous-agent.service
      script: /opt/afrique-sports-commentary/autonomous-match-agent.js
    - name: youtube-commentary
      script: /opt/afrique-sports-commentary/youtube-commentary-agent.js

local_machines:
  # iMac (Local Network) - RAG System for Afrique Sports
  imac:
    hostname: 192.168.2.217
    ssh_user: mad
    ssh_key: ~/.ssh/id_ed25519
    ssh_port: 22
    ssh_host_alias: imac  # Use: ssh imac

    # Hardware specs
    model: iMac (Mac15,4 - M3 chip)
    memory: 8 GB

    # Ollama configuration
    ollama:
      version: 0.13.5
      api_endpoint: http://localhost:11434
      models:
        - name: qwen2.5:14b
          size: 9.0 GB
          quantization: Q4_K_M
          parameter_size: 14.8B
      status: running

    # RAG system configuration
    rag:
      purpose: "Content retrieval and similarity search for Afrique Sports articles"
      vector_db: chromadb
      embedding_model: sentence-transformers/paraphrase-multilingual-mpnet-base-v2
      languages: [fr, en, es]
      base_path: ~/afrique-sports-rag
      status: active  # ✅ RUNNING

      # API endpoint (FastAPI)
      api:
        url: http://192.168.2.217:8100
        docs: http://192.168.2.217:8100/docs
        endpoints:
          health: GET /health
          stats: GET /stats
          search: POST /search
          context: POST /context
          ask: POST /ask
        screen_session: rag_api

      # Data sources
      sources:
        - name: real-france
          domain: real-france.fr
          articles: 9900
          topic: Real Madrid (French)
        - name: africatopsports
          domain: africatopsports.com
          articles: 8899
          topic: African football
        - name: le10sport
          domain: le10sport.com
          articles: 4399  # Growing to 20k
          topic: French football

      # Collection stats
      collection:
        name: afrique_sports_articles
        documents: 23196
        last_ingested: 2026-01-07

      directories:
        project: ~/afrique-sports-rag
        data: ~/afrique-sports-rag/data
        vector_db: ~/afrique-sports-rag/chromadb
        scripts: ~/afrique-sports-rag/scripts
        api: ~/afrique-sports-rag/api
        cache: ~/afrique-sports-rag/.cache

      features:
        - semantic_search
        - multilingual_embeddings
        - source_filtering
        - context_for_llm
        - similarity_scoring

  # MacBook Pro M1 Pro - Main development machine
  macbook_pro:
    model: MacBook Pro M1 Pro
    memory: 32 GB
    ollama:
      version: latest
      api_endpoint: http://localhost:11434
      models:
        - name: qwen2.5:14b-instruct
          size: 9.0 GB
      status: running
    purpose: "Main content generation (14B model with 32K context)"

database:
  provider: supabase
  url: https://kcarlszocimdxmzmljve.supabase.co
  tables:
    - match_commentary_ai
    - match_prematch_analysis
    - can_2025_youtube_streams

api:
  base_url: https://www.afriquesports.net
  webhook_secret_env: AI_AGENT_WEBHOOK_SECRET
  endpoints:
    - /api/can2025/live-commentary
    - /api/can2025/prematch-analysis
    - /api/can2025/youtube-stream
